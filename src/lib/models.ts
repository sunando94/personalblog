export const AVAILABLE_MODELS = [
  {
    id: "SmolLM2-135M-Instruct-q4f16_1-MLC",
    name: "SmolLM2 135M (Ultra-light)",
    size: "~200MB",
    description: "Extremely fast, minimal download footprint"
  },
  {
    id: "Qwen2.5-0.5B-Instruct-q4f16_1-MLC",
    name: "Qwen 2.5 0.5B (Tiny)",
    size: "~350MB",
    description: "Compact and capable for basic tasks"
  },
  {
    id: "SmolLM2-360M-Instruct-q4f16_1-MLC",
    name: "SmolLM2 360M (Efficient)",
    size: "~450MB",
    description: "Good balance of size and intelligence"
  },
  {
    id: "Llama-3.2-1B-Instruct-q4f32_1-MLC",
    name: "Llama 3.2 1B (Fast)",
    size: "~600MB",
    description: "Meta's lightweight model for quick responses"
  },
  {
    id: "Qwen2.5-1.5B-Instruct-q4f16_1-MLC",
    name: "Qwen 2.5 1.5B (Smart)",
    size: "~950MB",
    description: "Advanced logic in a sub-1GB package"
  },
  {
    id: "Gemma-2-2b-it-q4f16_1-MLC",
    name: "Gemma 2 2B (Popular)",
    size: "~1.4GB",
    description: "Google's state-of-the-art small model"
  },
  {
    id: "Llama-3.2-3B-Instruct-q4f32_1-MLC",
    name: "Llama 3.2 3B (Balanced)",
    size: "~1.8GB",
    description: "Best balance of speed and quality"
  },
  {
    id: "Qwen2.5-3B-Instruct-q4f16_1-MLC",
    name: "Qwen 2.5 3B (Advanced)",
    size: "~1.9GB",
    description: "Alibaba's multilingual powerhouse"
  },
  {
    id: "Phi-3.5-mini-instruct-q4f16_1-MLC",
    name: "Phi 3.5 Mini (Reasoning)",
    size: "~2.3GB",
    description: "Microsoft's efficient reasoning model"
  },
  {
    id: "Mistral-7B-Instruct-v0.3-q4f16_1-MLC",
    name: "Mistral 7B v0.3 (Pro)",
    size: "~4.2GB",
    description: "Industry-standard mid-size model"
  },
  {
    id: "Llama-3.1-8B-Instruct-q4f16_1-MLC",
    name: "Llama 3.1 8B (Powerhouse)",
    size: "~4.7GB",
    description: "Meta's flagship small model"
  },
  {
    id: "Hermes-3-Llama-3.1-8B-q4f16_1-MLC",
    name: "Hermes 3 Llama 8B (Deep)",
    size: "~4.7GB",
    description: "Advanced fine-tune for complex chat"
  }
];
